{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 5: Data cleaning and descriptive stats\n",
    "\n",
    "Overview of today's learning goals:\n",
    "\n",
    "  1. Introduce pandas\n",
    "  2. Load data files\n",
    "  3. Clean and process data\n",
    "  4. Select, filter, and slice data from a dataset\n",
    "  5. Descriptive stats: central tendency and dispersion\n",
    "  6. Merging and concatenating datasets\n",
    "  7. Grouping and summarizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# something new: import these packages to work with data\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducing pandas\n",
    "\n",
    "https://pandas.pydata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review: a python list is a built-in data type\n",
    "my_list = [8, 6, 4, 2]\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a numpy array is like a list\n",
    "# but faster, more compact, and lots more features\n",
    "my_array = np.array(my_list)\n",
    "my_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas has two primary data structures we will work with: Series and DataFrames\n",
    "\n",
    "### 1a. pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a pandas series is based on a numpy array: it's fast, compact, and has more functionality\n",
    "# perhaps most notably, it has an index which allows you to work naturally with tabular data\n",
    "my_series = pd.Series(my_list)\n",
    "my_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at a list-representation of the index\n",
    "my_series.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the series' values themselves\n",
    "my_series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the data type of the series' values?\n",
    "type(my_series.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the data type of the individual values themselves?\n",
    "my_series.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dict can contain multiple lists and label them\n",
    "my_dict = {'hh_income'  : [75125, 22075, 31950, 115400],\n",
    "           'home_value' : [525000, 275000, 395000, 985000]}\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a pandas dataframe can contain one or more columns\n",
    "# each column is a pandas series\n",
    "# each row is a pandas series\n",
    "# you can create a dataframe by passing in a list, array, series, or dict\n",
    "df = pd.DataFrame(my_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the row labels in the index are accessed by the .index attribute of the DataFrame object\n",
    "df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the column labels are accessed by the .columns attribute of the DataFrame object\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data values are accessed by the .values attribute of the DataFrame object\n",
    "# this is a numpy (two-dimensional) array\n",
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading data\n",
    "\n",
    "In practice, you'll work with data by loading a dataset file into pandas. CSV is the most common format. But pandas can also ingest tab-separated data, JSON, and proprietary file formats like Excel .xlsx files, Stata, SAS, and SPSS.\n",
    "\n",
    "Below, notice what pandas's `read_csv` function does:\n",
    "\n",
    "1. recognize the header row and get its variable names\n",
    "1. read all the rows and construct a pandas DataFrame (an assembly of pandas Series rows and columns)\n",
    "1. construct a unique index, beginning with zero\n",
    "1. infer the data type of each variable (ie, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a data file\n",
    "# note the relative filepath! where is this file located?\n",
    "# note the dtype argument! always specify that fips codes are strings, otherwise pandas guesses int\n",
    "df = pd.read_csv('../data/census_tracts_data_la.csv', dtype={'GEOID10':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe shape as rows, columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use len to just see the number of rows\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the dataframe's \"head\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the dataframe's \"tail\"\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are these data?\n",
    "\n",
    "I gathered them from the census bureau (2017 5-year tract-level ACS) for you, then gave them meaningful variable names. It's a set of socioeconomic variables across all LA County census tracts:\n",
    "\n",
    "|column|description|\n",
    "|------|-----------|\n",
    "|total_pop|Estimate!!SEX AND AGE!!Total population|\n",
    "|median_age|Estimate!!SEX AND AGE!!Total population!!Median age (years)|\n",
    "|pct_hispanic|Percent Estimate!!HISPANIC OR LATINO AND RACE!!Total population!!Hispanic or Latino (of any race)|\n",
    "|pct_white|Percent Estimate!!HISPANIC OR LATINO AND RACE!!Total population!!Not Hispanic or Latino!!White alone|\n",
    "|pct_black|Percent Estimate!!HISPANIC OR LATINO AND RACE!!Total population!!Not Hispanic or Latino!!Black or African American alone|\n",
    "|pct_asian|Estimate!!HISPANIC OR LATINO AND RACE!!Total population!!Not Hispanic or Latino!!Asian alone|\n",
    "|pct_male|Percent Estimate!!SEX AND AGE!!Total population!!Male|\n",
    "|pct_single_family_home|Percent Estimate!!UNITS IN STRUCTURE!!Total housing units!!1-unit detached|\n",
    "|med_home_value|Estimate!!VALUE!!Owner-occupied units!!Median (dollars)|\n",
    "|med_rooms_per_home|Estimate!!ROOMS!!Total housing units!!Median rooms|\n",
    "|pct_built_before_1940|Percent Estimate!!YEAR STRUCTURE BUILT!!Total housing units!!Built 1939 or earlier|\n",
    "|pct_renting|Percent Estimate!!HOUSING TENURE!!Occupied housing units!!Renter-occupied|\n",
    "|rental_vacancy_rate|Estimate!!HOUSING OCCUPANCY!!Total housing units!!Rental vacancy rate|\n",
    "|avg_renter_household_size|Estimate!!HOUSING TENURE!!Occupied housing units!!Average household size of renter-occupied unit|\n",
    "|med_gross_rent|Estimate!!GROSS RENT!!Occupied units paying rent!!Median (dollars)|\n",
    "|med_household_income|Estimate!!INCOME AND BENEFITS (IN 2017 INFLATION-ADJUSTED DOLLARS)!!Total households!!Median household income (dollars)|\n",
    "|mean_commute_time|Estimate!!COMMUTING TO WORK!!Workers 16 years and over!!Mean travel time to work (minutes)|\n",
    "|pct_commute_drive_alone|Percent Estimate!!COMMUTING TO WORK!!Workers 16 years and over!!Car truck or van drove alone|\n",
    "|pct_below_poverty|Percent Estimate!!PERCENTAGE OF FAMILIES AND PEOPLE WHOSE INCOME IN THE PAST 12 MONTHS IS BELOW THE POVERTY LEVEL!!All people|\n",
    "|pct_college_grad_student|Percent Estimate!!SCHOOL ENROLLMENT!!Population 3 years and over enrolled in school!!College or graduate school|\n",
    "|pct_same_residence_year_ago|Percent Estimate!!RESIDENCE 1 YEAR AGO!!Population 1 year and over!!Same house|\n",
    "|pct_bachelors_degree|Percent Estimate!!EDUCATIONAL ATTAINMENT!!Population 25 years and over!!Percent bachelor's degree or higher|\n",
    "|pct_english_only|Percent Estimate!!LANGUAGE SPOKEN AT HOME!!Population 5 years and over!!English only|\n",
    "|pct_foreign_born|Percent Estimate!!PLACE OF BIRTH!!Total population!!Foreign born|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data types of the columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access a single column like df['col_name']\n",
    "df['med_gross_rent'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas uses numpy's nan to represent null (missing) values\n",
    "print(np.nan)\n",
    "print(type(np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rent from string -> float\n",
    "df['med_gross_rent'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Didn't work! We need to clean up the stray alphabetical characters to get a numerical value. You can do string operations on pandas Series to clean up their values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a string replace and assign back to that column, then change type to float\n",
    "df['med_gross_rent'] = df['med_gross_rent'].str.replace(' (USD)', '', regex=False)\n",
    "df['med_gross_rent'] = df['med_gross_rent'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now clean up the income column then convert it from string -> float\n",
    "# do a string replace and assign back to that column\n",
    "df['med_household_income'] = df['med_household_income'].str.replace('$', '', regex=False)\n",
    "df['med_household_income'] = df['med_household_income'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rent from float -> int\n",
    "df['med_gross_rent'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You cannot store null values as type `int`, only as type `float`. You have three basic options:\n",
    "\n",
    "  1. Keep the column as float to retain the nulls - they are often important!\n",
    "  2. Drop all the rows that contain nulls if we need non-null data for our analysis\n",
    "  3. Fill in all the nulls with another value if we know a reliable default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows that contain nulls\n",
    "# this doesn't save the result, because we didn't reassign! (in reality, want to keep the nulls here)\n",
    "df.dropna(subset=['med_gross_rent']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in rows that contain nulls\n",
    "# this doesn't save the result, because we didn't reassign! (in reality, want to keep the nulls here)\n",
    "df['med_gross_rent'].fillna(value=0).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more string operations: slice state fips and county fips out of the tract fips string\n",
    "# assign them to new dataframe columns\n",
    "df['state'] = df['GEOID10'].str.slice(0, 2)\n",
    "df['county'] = df['GEOID10'].str.slice(2, 5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict that maps state fips code -> state name\n",
    "fips = {'04' : 'Arizona',\n",
    "        '06' : 'California',\n",
    "        '41' : 'Oregon'}\n",
    "\n",
    "# replace fips code with state name with the replace() method\n",
    "df['state'] = df['state'].replace(fips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can rename columns with the rename() method\n",
    "# remember to reassign to save the result\n",
    "df = df.rename(columns={'state' : 'state_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can drop columns you don't need with the drop() method\n",
    "# remember to reassign to save the result\n",
    "df = df.drop(columns=['county'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the cleaned-up dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it to disk as a \"clean\" copy\n",
    "# note the relative filepath\n",
    "df.to_csv('../data/census_tracts_data_la-clean.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Selecting and slicing data from a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHEAT SHEET OF COMMON TASKS\n",
    "# Operation                       Syntax           Result\n",
    "#------------------------------------------------------------\n",
    "# Select column by name           df[col]          Series\n",
    "# Select columns by name          df[col_list]     DataFrame\n",
    "# Select row by label             df.loc[label]    Series\n",
    "# Select row by integer location  df.iloc[loc]     Series\n",
    "# Slice rows by label             df.loc[a:c]      DataFrame\n",
    "# Select rows by boolean vector   df[mask]         DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Select DataFrame's column(s) by name\n",
    "\n",
    "We saw some of this a minute ago. Let's look in a bit more detail and break down what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a single column by column name\n",
    "# this is a pandas series\n",
    "df['total_pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select multiple columns by a list of column names\n",
    "# this is a pandas dataframe that is a subset of the original\n",
    "df[['total_pop', 'median_age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column by assigning df['new_col'] to some set of values\n",
    "# you can do math operations on any numeric columns\n",
    "df['monthly_income'] = df['med_household_income'] / 12\n",
    "df['rent_burden'] = df['med_gross_rent'] / df['monthly_income']\n",
    "\n",
    "# inspect the results\n",
    "df[['med_household_income', 'monthly_income', 'med_gross_rent', 'rent_burden']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Select row(s) by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .loc to select by row label\n",
    "# returns the row as a series whose index is the dataframe column names\n",
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .loc to select single value by row label, column name\n",
    "df.loc[0, 'pct_below_poverty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice of rows from label 5 to label 7, inclusive\n",
    "# this returns a pandas dataframe\n",
    "df.loc[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice of rows from label 5 to label 7, inclusive\n",
    "# slice of columns from pct_hispanic to pct_asian, inclusive\n",
    "df.loc[1:3, 'pct_hispanic':'pct_asian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset of rows from with labels in list\n",
    "# subset of columns with names in list\n",
    "df.loc[[1, 3], ['pct_hispanic', 'pct_asian']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use a column of unique identifiers as the index\n",
    "# fips codes uniquely identify each row (but verify!)\n",
    "df = df.set_index('GEOID10')\n",
    "df.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .loc works by label, not by position in the dataframe\n",
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the index now contains fips codes, so you have to use .loc accordingly to select by row label\n",
    "df.loc['06037137201']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Select by (integer) position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the row in the zero-th position in the dataframe\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can slice as well\n",
    "# note, while .loc[] is inclusive, .iloc[] is not\n",
    "# get the rows from position 0 up to but not including position 3 (ie, rows 0, 1, and 2)\n",
    "df.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value from the row in position 3 and the column in position 2 (zero-indexed)\n",
    "df.iloc[3, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4d. Select/filter by value\n",
    "\n",
    "You can subset or filter a dataframe for based on the values in its rows/columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the dataframe by rows with 30%+ rent burden\n",
    "df[df['rent_burden'] > 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what exactly did that do? let's break it out.\n",
    "df['rent_burden'] > 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essentially a true/false mask that filters by value\n",
    "mask = df['rent_burden'] > 0.3\n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can chain multiple conditions together\n",
    "# pandas logical operators are: | for or, & for and, ~ for not\n",
    "# these must be grouped by using parentheses due to order of operations\n",
    "# question: which tracts are both rent-burdened and majority-Black?\n",
    "mask = (df['rent_burden'] > 0.3) & (df['pct_black'] > 50)\n",
    "df[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which tracts are both rent-burdened and either majority-Black or majority-Hispanic?\n",
    "mask1 = df['rent_burden'] > 0.3\n",
    "mask2 = df['pct_black'] > 50\n",
    "mask3 = df['pct_hispanic'] > 50\n",
    "mask = mask1 & (mask2 | mask3)\n",
    "df[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the mask\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ means not... it essentially flips trues to falses and vice-versa\n",
    "~mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which rows are in a state that begins with \"Cal\"?\n",
    "# all of them... because we're looking only at LA county\n",
    "mask = df['state_name'].str.startswith('Cal')\n",
    "df[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# create a new subset dataframe containing all the rows with median home values above $800,000 and percent-White above 60%\n",
    "# how many rows did you get?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what share of majority-White tracts are rent burdened?\n",
    "mask1 = df['pct_white'] > 50\n",
    "mask2 = mask1 & (df['rent_burden'] > 0.3)\n",
    "len(df[mask2]) / len(df[mask1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what share of majority-Hispanic tracts are rent burdened?\n",
    "mask1 = df['pct_hispanic'] > 50\n",
    "mask2 = mask1 & (df['rent_burden'] > 0.3)\n",
    "len(df[mask2]) / len(df[mask1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can sort the dataframe by values in some column\n",
    "df.sort_values('pct_below_poverty', ascending=False).dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the describe() method to pull basic descriptive stats for some column\n",
    "df['med_household_income'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or if you need the value of a single stat, call it directly\n",
    "\n",
    "Key measures of central tendency: mean and median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean, or \"average\" value\n",
    "df['med_household_income'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the median, or \"typical\" (ie, 50th percentile) value\n",
    "df['med_household_income'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# create a new subset dataframe containing rows with median household income above the (tract) average in LA county\n",
    "# what is the median median home value across this subset of tracts?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key measures of dispersion or variability: range, IQR, variance, standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['med_household_income'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which tract has the lowest median household income?\n",
    "df['med_household_income'].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['med_household_income'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the 90th-percentile value?\n",
    "df['med_household_income'].quantile(0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the distribution's range\n",
    "df['med_household_income'].max() - df['med_household_income'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate its IQR\n",
    "df['med_household_income'].quantile(0.75) - df['med_household_income'].quantile(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate its variance... rarely used in practice\n",
    "df['med_household_income'].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate its standard deviation\n",
    "# this is the sqrt of the variance... putting it into same units as the variable itself\n",
    "df['med_household_income'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# what's the average (mean) median home value across majority-White tracts? And across majority-Black tracts?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Merge and concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a. Merging DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subset dataframe with only race/ethnicity variables\n",
    "race_cols = ['pct_asian', 'pct_black', 'pct_hispanic', 'pct_white']\n",
    "df_race = df[race_cols]\n",
    "df_race.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subset dataframe with only economic variables\n",
    "econ_cols = ['med_home_value', 'med_household_income']\n",
    "df_econ = df[econ_cols].sort_values('med_household_income')\n",
    "df_econ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge them together, aligning rows based on their labels in the index\n",
    "df_merged = pd.merge(left=df_econ, right=df_race, how='inner', left_index=True, right_index=True)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset df_econ's index\n",
    "df_econ = df_econ.reset_index()\n",
    "df_econ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge them together, aligning rows based on their labels in the index\n",
    "# doesn't work! their indexes do not share any labels to match/align the rows\n",
    "df_merged = pd.merge(left=df_econ, right=df_race, how='inner', left_index=True, right_index=True)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# change the \"how\" argument: what happens if you try an \"outer\" join? or a \"left\" join? or a \"right\" join?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead merge where df_race index matches df_econ GEOID10 column\n",
    "df_merged = pd.merge(left=df_econ, right=df_race, how='inner', left_on='GEOID10', right_index=True)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b. Concatenating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the orange county tracts data\n",
    "oc = pd.read_csv('../data/census_tracts_data_oc.csv', dtype={'GEOID10':str})\n",
    "oc = oc.set_index('GEOID10')\n",
    "oc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging joins data together aligned by the index, but concatenating just smushes it together along some axis\n",
    "df_all = pd.concat([df, oc], sort=False)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Grouping and summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract county fips from index then replace with friendly name\n",
    "df_all['county'] = df_all.index.str.slice(2, 5)\n",
    "df_all['county'] = df_all['county'].replace({'037':'LA', '059':'OC'})\n",
    "df_all['county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the rows by county\n",
    "counties = df_all.groupby('county')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the median pct_white across the tracts in each county?\n",
    "counties['pct_white'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at several columns' medians by county\n",
    "counties[['pct_bachelors_degree', 'pct_foreign_born', 'pct_commute_drive_alone']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# group the tracts by county and find the highest/lowest tract percentages that speak English-only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ppd534)",
   "language": "python",
   "name": "ox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
